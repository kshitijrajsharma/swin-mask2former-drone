{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50bd885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:06:59.828665Z",
     "iopub.status.busy": "2026-01-02T03:06:59.828382Z",
     "iopub.status.idle": "2026-01-02T03:07:13.953946Z",
     "shell.execute_reply": "2026-01-02T03:07:13.953155Z"
    },
    "papermill": {
     "duration": 14.131585,
     "end_time": "2026-01-02T03:07:13.955763",
     "exception": false,
     "start_time": "2026-01-02T03:06:59.824178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, re, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e01eb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:13.961933Z",
     "iopub.status.busy": "2026-01-02T03:07:13.961281Z",
     "iopub.status.idle": "2026-01-02T03:07:13.968117Z",
     "shell.execute_reply": "2026-01-02T03:07:13.967560Z"
    },
    "papermill": {
     "duration": 0.011384,
     "end_time": "2026-01-02T03:07:13.969541",
     "exception": false,
     "start_time": "2026-01-02T03:07:13.958157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    ROOT: str = \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared\"  \n",
    "    TRAIN_DIR: str = \"train\"\n",
    "    VAL_DIR: str = \"val\"\n",
    "\n",
    "    USE_RGB: bool = True\n",
    "    USE_MS: bool  = True\n",
    "    USE_HS: bool  = True\n",
    "\n",
    "    LOAD_SIZE:int = 64\n",
    "    IMG_SIZE: int = 64\n",
    "\n",
    "    BATCH_SIZE: int = 128  \n",
    "    EPOCHS: int = 100\n",
    "    LR: float = 2e-4\n",
    "    WD: float = 0.05\n",
    "\n",
    "    NUM_WORKERS: int = 4\n",
    "    SEED: int = 3557\n",
    "\n",
    "    RGB_BACKBONE: str = \"convnext_base\"  \n",
    "    AMP: bool = True\n",
    "\n",
    "    HS_DROP_FIRST: int = 10\n",
    "    HS_DROP_LAST: int = 14\n",
    "\n",
    "    OUT_DIR: str = \"/kaggle/working/\"\n",
    "    BEST_CKPT: str = \"best.pt\"\n",
    "\n",
    "\n",
    "LABELS = [\"Health\", \"Rust\", \"Other\"]\n",
    "LBL2ID = {k: i for i, k in enumerate(LABELS)}\n",
    "ID2LBL = {i: k for k, i in LBL2ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b007bd22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:13.974901Z",
     "iopub.status.busy": "2026-01-02T03:07:13.974665Z",
     "iopub.status.idle": "2026-01-02T03:07:13.988327Z",
     "shell.execute_reply": "2026-01-02T03:07:13.987785Z"
    },
    "papermill": {
     "duration": 0.018123,
     "end_time": "2026-01-02T03:07:13.989710",
     "exception": false,
     "start_time": "2026-01-02T03:07:13.971587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def list_files(folder: str, exts: Tuple[str, ...]) -> List[str]:\n",
    "    if not os.path.isdir(folder):\n",
    "        return []\n",
    "    out = []\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(exts):\n",
    "            out.append(os.path.join(folder, fn))\n",
    "    return sorted(out)\n",
    "\n",
    "def base_id(path: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def parse_label_from_train_name(bid: str) -> Optional[str]:\n",
    "    m = re.match(r\"^(Health|Rust|Other)_\", bid)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def build_index(root: str, split: str) -> Dict[str, Dict[str, str]]:\n",
    "    split_dir = os.path.join(root, split)\n",
    "    rgb_dir = os.path.join(split_dir, \"RGB\")\n",
    "    ms_dir  = os.path.join(split_dir, \"MS\")\n",
    "    hs_dir  = os.path.join(split_dir, \"HS\")\n",
    "\n",
    "    rgb_files = list_files(rgb_dir, (\".png\", \".jpg\", \".jpeg\"))\n",
    "    ms_files  = list_files(ms_dir, (\".tif\", \".tiff\"))\n",
    "    hs_files  = list_files(hs_dir, (\".tif\", \".tiff\"))\n",
    "\n",
    "    idx: Dict[str, Dict[str, str]] = {}\n",
    "    for p in rgb_files:\n",
    "        idx.setdefault(base_id(p), {})[\"rgb\"] = p\n",
    "    for p in ms_files:\n",
    "        idx.setdefault(base_id(p), {})[\"ms\"] = p\n",
    "    for p in hs_files:\n",
    "        idx.setdefault(base_id(p), {})[\"hs\"] = p\n",
    "    return idx\n",
    "    \n",
    "def center_crop(x: torch.Tensor, size: int) -> torch.Tensor:\n",
    "    _, h, w = x.shape\n",
    "    top = (h - size) // 2\n",
    "    left = (w - size) // 2\n",
    "    return x[:, top:top+size, left:left+size]\n",
    "\n",
    "def random_crop(x: torch.Tensor, size: int) -> torch.Tensor:\n",
    "    _, h, w = x.shape\n",
    "    if h == size and w == size:\n",
    "        return x\n",
    "    top = random.randint(0, h - size)\n",
    "    left = random.randint(0, w - size)\n",
    "    return x[:, top:top+size, left:left+size]\n",
    "    \n",
    "def make_train_df(train_idx: Dict[str, Dict[str, str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for bid, paths in train_idx.items():\n",
    "        lab = parse_label_from_train_name(bid)\n",
    "        if lab is None:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"base_id\": bid,\n",
    "            \"label\": lab,\n",
    "            \"rgb\": paths.get(\"rgb\"),\n",
    "            \"ms\":  paths.get(\"ms\"),\n",
    "            \"hs\":  paths.get(\"hs\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def make_val_df(val_idx: Dict[str, Dict[str, str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for bid, paths in val_idx.items():\n",
    "        rows.append({\n",
    "            \"base_id\": bid,\n",
    "            \"rgb\": paths.get(\"rgb\"),\n",
    "            \"ms\":  paths.get(\"ms\"),\n",
    "            \"hs\":  paths.get(\"hs\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def stratified_holdout(df: pd.DataFrame, frac: float = 0.1, seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    parts = []\n",
    "    for lab, g in df.groupby(\"label\"):\n",
    "        n = max(1, int(len(g) * frac))\n",
    "        parts.append(g.iloc[:n])\n",
    "    df_va = pd.concat(parts).drop_duplicates(\"base_id\")\n",
    "    df_tr = df[~df[\"base_id\"].isin(df_va[\"base_id\"])].reset_index(drop=True)\n",
    "    df_va = df_va.reset_index(drop=True)\n",
    "    return df_tr, df_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5112e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:13.994907Z",
     "iopub.status.busy": "2026-01-02T03:07:13.994674Z",
     "iopub.status.idle": "2026-01-02T03:07:14.008832Z",
     "shell.execute_reply": "2026-01-02T03:07:14.008318Z"
    },
    "papermill": {
     "duration": 0.018385,
     "end_time": "2026-01-02T03:07:14.010148",
     "exception": false,
     "start_time": "2026-01-02T03:07:13.991763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "def fix_channels(x: torch.Tensor, target_c: int) -> torch.Tensor:\n",
    "    # x: (C,H,W) -> (target_c,H,W) by crop or zero-pad\n",
    "    c, h, w = x.shape\n",
    "    if c == target_c:\n",
    "        return x\n",
    "    if c > target_c:\n",
    "        return x[:target_c]\n",
    "    pad = torch.zeros((target_c - c, h, w), dtype=x.dtype)\n",
    "    return torch.cat([x, pad], dim=0)\n",
    "    \n",
    "def read_rgb(path: str) -> torch.Tensor:\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    x = torch.from_numpy(img).permute(2, 0, 1)  # (3,H,W)\n",
    "    x = (x - IMAGENET_MEAN) / IMAGENET_STD      \n",
    "    return x\n",
    "\n",
    "def read_tiff_multiband(path: str) -> np.ndarray:\n",
    "    arr = tiff.imread(path)  # (H,W,C) or (C,H,W)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D TIFF, got {arr.shape} for {path}\")\n",
    "    if arr.shape[0] < arr.shape[1] and arr.shape[0] < arr.shape[2]:\n",
    "        arr = np.transpose(arr, (1, 2, 0))  # -> (H,W,C)\n",
    "    return arr\n",
    "\n",
    "def normalize_per_band_minmax(x: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    H, W, C = x.shape\n",
    "    flat = x.reshape(-1, C)\n",
    "    mn = flat.min(axis=0)\n",
    "    mx = flat.max(axis=0)\n",
    "    denom = (mx - mn)\n",
    "    denom[denom < eps] = 1.0\n",
    "    x = (x - mn.reshape(1, 1, C)) / denom.reshape(1, 1, C)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "def read_ms(path: str) -> torch.Tensor:\n",
    "    arr = read_tiff_multiband(path)           # (H,W,5)\n",
    "    arr = normalize_per_band_minmax(arr)\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1)  # (5,H,W)\n",
    "\n",
    "def read_hs(path: str, drop_first: int, drop_last: int) -> torch.Tensor:\n",
    "    arr = read_tiff_multiband(path)           # (H,W,B)\n",
    "    B = arr.shape[2]\n",
    "    if B > (drop_first + drop_last + 1):\n",
    "        arr = arr[:, :, drop_first:B - drop_last]\n",
    "    arr = normalize_per_band_minmax(arr)\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1)  # (B',H,W)\n",
    "\n",
    "def resize_tensor(x: torch.Tensor, size: int) -> torch.Tensor:\n",
    "    # x: (C,H,W) -> (C,size,size)\n",
    "    return F.interpolate(x.unsqueeze(0), size=(size, size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "def apply_joint_aug(x_rgb, x_ms, x_hs):\n",
    "    k = random.randint(0, 3)\n",
    "    do_h = random.random() < 0.5\n",
    "    do_v = random.random() < 0.5\n",
    "\n",
    "    def _tf(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        if k:\n",
    "            x = torch.rot90(x, k, dims=(1, 2))\n",
    "        if do_h:\n",
    "            x = torch.flip(x, dims=(2,))\n",
    "        if do_v:\n",
    "            x = torch.flip(x, dims=(1,))\n",
    "        return x\n",
    "\n",
    "    return _tf(x_rgb), _tf(x_ms), _tf(x_hs)\n",
    "\n",
    "def infer_hs_in_ch(df_train: pd.DataFrame, df_val: pd.DataFrame, cfg: CFG) -> int:\n",
    "    for df in (df_train, df_val):\n",
    "        if \"hs\" in df.columns:\n",
    "            for p in df[\"hs\"].dropna().tolist():\n",
    "                if p and os.path.exists(p):\n",
    "                    x = read_hs(p, cfg.HS_DROP_FIRST, cfg.HS_DROP_LAST)\n",
    "                    return int(x.shape[0])\n",
    "    return 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "497983a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:14.015610Z",
     "iopub.status.busy": "2026-01-02T03:07:14.015380Z",
     "iopub.status.idle": "2026-01-02T03:07:14.024664Z",
     "shell.execute_reply": "2026-01-02T03:07:14.024061Z"
    },
    "papermill": {
     "duration": 0.013756,
     "end_time": "2026-01-02T03:07:14.026025",
     "exception": false,
     "start_time": "2026-01-02T03:07:14.012269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WheatMultiModalDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, cfg: CFG, hs_in_ch: int, train: bool):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.hs_in_ch = hs_in_ch\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        row = self.df.iloc[i]\n",
    "        bid = row[\"base_id\"]\n",
    "\n",
    "        x_rgb = x_ms = x_hs = None\n",
    "        m_rgb = m_ms = m_hs = 0.0\n",
    "\n",
    "        if self.cfg.USE_RGB and row.get(\"rgb\") is not None:\n",
    "            x_rgb = read_rgb(row[\"rgb\"])\n",
    "            x_rgb = resize_tensor(x_rgb, self.cfg.LOAD_SIZE)\n",
    "            x_rgb = random_crop(x_rgb, self.cfg.IMG_SIZE) if self.train else center_crop(x_rgb, self.cfg.IMG_SIZE)\n",
    "            m_rgb = 1.0\n",
    "\n",
    "        if self.cfg.USE_MS and row.get(\"ms\") is not None:\n",
    "            x_ms = read_ms(row[\"ms\"])\n",
    "            x_ms = resize_tensor(x_ms, self.cfg.LOAD_SIZE)\n",
    "            x_ms = random_crop(x_ms, self.cfg.IMG_SIZE) if self.train else center_crop(x_ms, self.cfg.IMG_SIZE)\n",
    "            m_ms = 1.0\n",
    "\n",
    "\n",
    "        if self.cfg.USE_HS and isinstance(row.get(\"hs\"), str) and row[\"hs\"]:\n",
    "            x_hs = read_hs(row[\"hs\"], self.cfg.HS_DROP_FIRST, self.cfg.HS_DROP_LAST)\n",
    "            x_hs = fix_channels(x_hs, self.hs_in_ch) \n",
    "            x_hs = resize_tensor(x_hs, self.cfg.LOAD_SIZE)\n",
    "            x_hs = random_crop(x_hs, self.cfg.IMG_SIZE) if self.train else center_crop(x_hs, self.cfg.IMG_SIZE)\n",
    "            m_hs = 1.0\n",
    "    \n",
    "        if self.train:\n",
    "            x_rgb, x_ms, x_hs = apply_joint_aug(x_rgb, x_ms, x_hs)\n",
    "\n",
    "        if self.cfg.USE_RGB and x_rgb is None:\n",
    "            x_rgb = torch.zeros(3, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "        if self.cfg.USE_MS and x_ms is None:\n",
    "            x_ms = torch.zeros(5, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "        if self.cfg.USE_HS and x_hs is None:\n",
    "            x_hs = torch.zeros(self.hs_in_ch, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "\n",
    "        mask = torch.tensor([m_rgb, m_ms, m_hs], dtype=torch.float32)\n",
    "\n",
    "        if \"label\" in row:\n",
    "            y = LBL2ID[row[\"label\"]]\n",
    "            return {\"id\": bid, \"rgb\": x_rgb, \"ms\": x_ms, \"hs\": x_hs, \"mask\": mask, \"y\": torch.tensor(y, dtype=torch.long)}\n",
    "        else:\n",
    "            return {\"id\": bid, \"rgb\": x_rgb, \"ms\": x_ms, \"hs\": x_hs, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9ee5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:14.031458Z",
     "iopub.status.busy": "2026-01-02T03:07:14.031142Z",
     "iopub.status.idle": "2026-01-02T03:07:14.041840Z",
     "shell.execute_reply": "2026-01-02T03:07:14.041077Z"
    },
    "papermill": {
     "duration": 0.01512,
     "end_time": "2026-01-02T03:07:14.043254",
     "exception": false,
     "start_time": "2026-01-02T03:07:14.028134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmallSpectralEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, emb_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, emb_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block(x)\n",
    "        return self.head(x)\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, cfg: CFG, hs_in_ch: int, n_classes: int = 3):\n",
    "        super().__init__()\n",
    "        self.use_rgb = cfg.USE_RGB\n",
    "        self.use_ms  = cfg.USE_MS\n",
    "        self.use_hs  = cfg.USE_HS\n",
    "\n",
    "        feat_dims = []\n",
    "\n",
    "        if self.use_rgb:\n",
    "            self.rgb_enc = timm.create_model(cfg.RGB_BACKBONE, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
    "            rgb_dim = self.rgb_enc.num_features\n",
    "            feat_dims.append(rgb_dim)\n",
    "        else:\n",
    "            self.rgb_enc = None\n",
    "\n",
    "        if self.use_ms:\n",
    "            self.ms_enc = SmallSpectralEncoder(in_ch=5, emb_dim=256)\n",
    "            feat_dims.append(256)\n",
    "        else:\n",
    "            self.ms_enc = None\n",
    "\n",
    "        if self.use_hs:\n",
    "            self.hs_enc = SmallSpectralEncoder(in_ch=hs_in_ch, emb_dim=256)\n",
    "            feat_dims.append(256)\n",
    "        else:\n",
    "            self.hs_enc = None\n",
    "\n",
    "        fusion_dim = sum(feat_dims)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, rgb, ms, hs, mask):\n",
    "        feats = []\n",
    "        if self.use_rgb:\n",
    "            feats.append(self.rgb_enc(rgb) * mask[:, 0:1])\n",
    "        if self.use_ms:\n",
    "            feats.append(self.ms_enc(ms) * mask[:, 1:2])\n",
    "        if self.use_hs:\n",
    "            feats.append(self.hs_enc(hs) * mask[:, 2:3])\n",
    "\n",
    "        f = torch.cat(feats, dim=1)\n",
    "        return self.classifier(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0645e058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:14.048704Z",
     "iopub.status.busy": "2026-01-02T03:07:14.048459Z",
     "iopub.status.idle": "2026-01-02T03:07:14.059785Z",
     "shell.execute_reply": "2026-01-02T03:07:14.059057Z"
    },
    "papermill": {
     "duration": 0.015767,
     "end_time": "2026-01-02T03:07:14.061161",
     "exception": false,
     "start_time": "2026-01-02T03:07:14.045394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    conf = np.zeros((3, 3), dtype=np.int64)\n",
    "\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        y    = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(rgb, ms, hs, mask)\n",
    "        pred = logits.argmax(dim=1)\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y).sum().item()\n",
    "\n",
    "        yt = y.cpu().numpy()\n",
    "        yp = pred.cpu().numpy()\n",
    "        for t, p in zip(yt, yp):\n",
    "            conf[t, p] += 1\n",
    "\n",
    "    acc = correct / max(1, total)\n",
    "\n",
    "    f1s = []\n",
    "    for c in range(3):\n",
    "        tp = conf[c, c]\n",
    "        fp = conf[:, c].sum() - tp\n",
    "        fn = conf[c, :].sum() - tp\n",
    "        prec = tp / max(1, (tp + fp))\n",
    "        rec  = tp / max(1, (tp + fn))\n",
    "        f1 = 0.0 if (prec + rec) == 0 else (2 * prec * rec / (prec + rec))\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return {\"acc\": float(acc), \"macro_f1\": float(np.mean(f1s))}\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, n = 0.0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        y    = batch[\"y\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
    "            logits = model(rgb, ms, hs, mask)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / max(1, n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ids = []\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "\n",
    "        logits = model(rgb, ms, hs, mask)\n",
    "        p = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        preds.extend([ID2LBL[x] for x in p])\n",
    "        ids.extend(batch[\"id\"])\n",
    "    return ids, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e235951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:07:14.067093Z",
     "iopub.status.busy": "2026-01-02T03:07:14.066339Z",
     "iopub.status.idle": "2026-01-02T03:26:46.205902Z",
     "shell.execute_reply": "2026-01-02T03:26:46.204707Z"
    },
    "papermill": {
     "duration": 1172.144677,
     "end_time": "2026-01-02T03:26:46.207981",
     "exception": false,
     "start_time": "2026-01-02T03:07:14.063304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Backbone: convnext_base\n",
      "Indexed train IDs: 600 | usable labeled train rows: 600\n",
      "Indexed val IDs:   300   | val rows: 300\n",
      "Inferred HS channels after trimming: 101\n",
      "Train split: 540 | Holdout split: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da7c77c3c904271a56862db18f364e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2339711548.py:58: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.AMP and device.type == \"cuda\"))\n",
      "/tmp/ipykernel_23/640892646.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=1.0346 | val_acc=0.6333 | val_macroF1=0.5758\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 02 | loss=0.8718 | val_acc=0.6333 | val_macroF1=0.5758\n",
      "Epoch 03 | loss=0.8221 | val_acc=0.6833 | val_macroF1=0.6629\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 04 | loss=0.7524 | val_acc=0.6500 | val_macroF1=0.5910\n",
      "Epoch 05 | loss=0.6689 | val_acc=0.6667 | val_macroF1=0.6579\n",
      "Epoch 06 | loss=0.6329 | val_acc=0.6000 | val_macroF1=0.5751\n",
      "Epoch 07 | loss=0.5617 | val_acc=0.6000 | val_macroF1=0.5803\n",
      "Epoch 08 | loss=0.5224 | val_acc=0.7000 | val_macroF1=0.6942\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 09 | loss=0.4540 | val_acc=0.7167 | val_macroF1=0.7051\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 10 | loss=0.3775 | val_acc=0.6833 | val_macroF1=0.6795\n",
      "Epoch 11 | loss=0.3395 | val_acc=0.7167 | val_macroF1=0.6985\n",
      "Epoch 12 | loss=0.2882 | val_acc=0.6500 | val_macroF1=0.6496\n",
      "Epoch 13 | loss=0.2263 | val_acc=0.6667 | val_macroF1=0.6657\n",
      "Epoch 14 | loss=0.1776 | val_acc=0.7000 | val_macroF1=0.6908\n",
      "Epoch 15 | loss=0.1906 | val_acc=0.6833 | val_macroF1=0.6621\n",
      "Epoch 16 | loss=0.1519 | val_acc=0.6833 | val_macroF1=0.6716\n",
      "Epoch 17 | loss=0.1198 | val_acc=0.6833 | val_macroF1=0.6770\n",
      "Epoch 18 | loss=0.0795 | val_acc=0.6833 | val_macroF1=0.6779\n",
      "Epoch 19 | loss=0.0827 | val_acc=0.6833 | val_macroF1=0.6786\n",
      "Epoch 20 | loss=0.0594 | val_acc=0.6500 | val_macroF1=0.6469\n",
      "Epoch 21 | loss=0.0541 | val_acc=0.6667 | val_macroF1=0.6571\n",
      "Epoch 22 | loss=0.0598 | val_acc=0.6833 | val_macroF1=0.6764\n",
      "Epoch 23 | loss=0.0548 | val_acc=0.7333 | val_macroF1=0.7262\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 24 | loss=0.0646 | val_acc=0.7167 | val_macroF1=0.7157\n",
      "Epoch 25 | loss=0.0465 | val_acc=0.7167 | val_macroF1=0.7160\n",
      "Epoch 26 | loss=0.0543 | val_acc=0.7333 | val_macroF1=0.7263\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 27 | loss=0.0406 | val_acc=0.7167 | val_macroF1=0.7127\n",
      "Epoch 28 | loss=0.0427 | val_acc=0.7000 | val_macroF1=0.7010\n",
      "Epoch 29 | loss=0.0484 | val_acc=0.7000 | val_macroF1=0.6939\n",
      "Epoch 30 | loss=0.0391 | val_acc=0.7000 | val_macroF1=0.6947\n",
      "Epoch 31 | loss=0.0427 | val_acc=0.6667 | val_macroF1=0.6598\n",
      "Epoch 32 | loss=0.0442 | val_acc=0.7000 | val_macroF1=0.6949\n",
      "Epoch 33 | loss=0.0453 | val_acc=0.7000 | val_macroF1=0.6978\n",
      "Epoch 34 | loss=0.0522 | val_acc=0.7167 | val_macroF1=0.7133\n",
      "Epoch 35 | loss=0.0461 | val_acc=0.7167 | val_macroF1=0.6996\n",
      "Epoch 36 | loss=0.0411 | val_acc=0.7000 | val_macroF1=0.6962\n",
      "Epoch 37 | loss=0.0593 | val_acc=0.7000 | val_macroF1=0.6901\n",
      "Epoch 38 | loss=0.0526 | val_acc=0.7000 | val_macroF1=0.6981\n",
      "Epoch 39 | loss=0.0395 | val_acc=0.6833 | val_macroF1=0.6827\n",
      "Epoch 40 | loss=0.0352 | val_acc=0.6500 | val_macroF1=0.6483\n",
      "Epoch 41 | loss=0.0454 | val_acc=0.6833 | val_macroF1=0.6836\n",
      "Epoch 42 | loss=0.0347 | val_acc=0.7000 | val_macroF1=0.6992\n",
      "Epoch 43 | loss=0.0619 | val_acc=0.6833 | val_macroF1=0.6810\n",
      "Epoch 44 | loss=0.0524 | val_acc=0.7000 | val_macroF1=0.6953\n",
      "Epoch 45 | loss=0.0650 | val_acc=0.7167 | val_macroF1=0.7051\n",
      "Epoch 46 | loss=0.0851 | val_acc=0.7167 | val_macroF1=0.7144\n",
      "Epoch 47 | loss=0.0762 | val_acc=0.7833 | val_macroF1=0.7828\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 48 | loss=0.0627 | val_acc=0.7500 | val_macroF1=0.7503\n",
      "Epoch 49 | loss=0.0579 | val_acc=0.7000 | val_macroF1=0.6990\n",
      "Epoch 50 | loss=0.0399 | val_acc=0.7167 | val_macroF1=0.7095\n",
      "Epoch 51 | loss=0.0296 | val_acc=0.7000 | val_macroF1=0.6960\n",
      "Epoch 52 | loss=0.0332 | val_acc=0.7167 | val_macroF1=0.7143\n",
      "Epoch 53 | loss=0.0345 | val_acc=0.7000 | val_macroF1=0.6986\n",
      "Epoch 54 | loss=0.0422 | val_acc=0.7333 | val_macroF1=0.7313\n",
      "Epoch 55 | loss=0.0294 | val_acc=0.7333 | val_macroF1=0.7366\n",
      "Epoch 56 | loss=0.0318 | val_acc=0.7167 | val_macroF1=0.7191\n",
      "Epoch 57 | loss=0.0352 | val_acc=0.8000 | val_macroF1=0.7963\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 58 | loss=0.0308 | val_acc=0.7500 | val_macroF1=0.7404\n",
      "Epoch 59 | loss=0.0328 | val_acc=0.7500 | val_macroF1=0.7535\n",
      "Epoch 60 | loss=0.0416 | val_acc=0.7000 | val_macroF1=0.6939\n",
      "Epoch 61 | loss=0.0330 | val_acc=0.6333 | val_macroF1=0.5993\n",
      "Epoch 62 | loss=0.0387 | val_acc=0.6333 | val_macroF1=0.5990\n",
      "Epoch 63 | loss=0.0303 | val_acc=0.6833 | val_macroF1=0.6744\n",
      "Epoch 64 | loss=0.0353 | val_acc=0.7000 | val_macroF1=0.7033\n",
      "Epoch 65 | loss=0.0304 | val_acc=0.7333 | val_macroF1=0.7373\n",
      "Epoch 66 | loss=0.0298 | val_acc=0.7333 | val_macroF1=0.7373\n",
      "Epoch 67 | loss=0.0306 | val_acc=0.7333 | val_macroF1=0.7373\n",
      "Epoch 68 | loss=0.0312 | val_acc=0.7333 | val_macroF1=0.7349\n",
      "Epoch 69 | loss=0.0312 | val_acc=0.7333 | val_macroF1=0.7349\n",
      "Epoch 70 | loss=0.0265 | val_acc=0.7000 | val_macroF1=0.6985\n",
      "Epoch 71 | loss=0.0287 | val_acc=0.7000 | val_macroF1=0.6985\n",
      "Epoch 72 | loss=0.0317 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 73 | loss=0.0284 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 74 | loss=0.0318 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 75 | loss=0.0292 | val_acc=0.7167 | val_macroF1=0.7178\n",
      "Epoch 76 | loss=0.0281 | val_acc=0.7000 | val_macroF1=0.7011\n",
      "Epoch 77 | loss=0.0291 | val_acc=0.7000 | val_macroF1=0.7011\n",
      "Epoch 78 | loss=0.0282 | val_acc=0.7000 | val_macroF1=0.7011\n",
      "Epoch 79 | loss=0.0295 | val_acc=0.7167 | val_macroF1=0.7178\n",
      "Epoch 80 | loss=0.0286 | val_acc=0.7167 | val_macroF1=0.7178\n",
      "Epoch 81 | loss=0.0289 | val_acc=0.7333 | val_macroF1=0.7333\n",
      "Epoch 82 | loss=0.0295 | val_acc=0.7333 | val_macroF1=0.7333\n",
      "Epoch 83 | loss=0.0312 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 84 | loss=0.0301 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 85 | loss=0.0276 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 86 | loss=0.0266 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 87 | loss=0.0267 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 88 | loss=0.0288 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 89 | loss=0.0272 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 90 | loss=0.0249 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 91 | loss=0.0281 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 92 | loss=0.0280 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 93 | loss=0.0253 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 94 | loss=0.0296 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 95 | loss=0.0286 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 96 | loss=0.0261 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 97 | loss=0.0276 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 98 | loss=0.0295 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 99 | loss=0.0284 | val_acc=0.7167 | val_macroF1=0.7161\n",
      "Epoch 100 | loss=0.0291 | val_acc=0.7167 | val_macroF1=0.7161\n"
     ]
    }
   ],
   "source": [
    "cfg = CFG()\n",
    "seed_everything(cfg.SEED)\n",
    "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Backbone:\", cfg.RGB_BACKBONE)\n",
    "\n",
    "train_idx = build_index(cfg.ROOT, cfg.TRAIN_DIR)\n",
    "val_idx   = build_index(cfg.ROOT, cfg.VAL_DIR)\n",
    "\n",
    "train_df = make_train_df(train_idx)\n",
    "val_df   = make_val_df(val_idx)\n",
    "\n",
    "print(f\"Indexed train IDs: {len(train_idx)} | usable labeled train rows: {len(train_df)}\")\n",
    "print(f\"Indexed val IDs:   {len(val_idx)}   | val rows: {len(val_df)}\")\n",
    "\n",
    "if len(train_df) == 0:\n",
    "    raise RuntimeError(\"No training samples found. Check ROOT/train and filename label pattern (Health_/Rust_/Other_).\")\n",
    "\n",
    "hs_in_ch = infer_hs_in_ch(train_df, val_df, cfg)\n",
    "print(\"Inferred HS channels after trimming:\", hs_in_ch)\n",
    "\n",
    "df_tr, df_va = stratified_holdout(train_df, frac=0.1, seed=cfg.SEED)\n",
    "print(f\"Train split: {len(df_tr)} | Holdout split: {len(df_va)}\")\n",
    "\n",
    "ds_tr = WheatMultiModalDataset(df_tr, cfg, hs_in_ch=hs_in_ch, train=True)\n",
    "ds_va = WheatMultiModalDataset(df_va, cfg, hs_in_ch=hs_in_ch, train=False)\n",
    "ds_te = WheatMultiModalDataset(val_df, cfg, hs_in_ch=hs_in_ch, train=False)\n",
    "\n",
    "dl_tr = DataLoader(ds_tr, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                   num_workers=4, pin_memory=True, drop_last=True,\n",
    "                   persistent_workers=True, prefetch_factor=4)\n",
    "\n",
    "dl_va = DataLoader(ds_va, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                   num_workers=4, pin_memory=True,\n",
    "                   persistent_workers=True, prefetch_factor=4)\n",
    "\n",
    "dl_te = DataLoader(ds_te, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                   num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "model = MultiModalNet(cfg, hs_in_ch=hs_in_ch, n_classes=3).to(device)\n",
    "\n",
    "backbone, head = [], []\n",
    "for n, p in model.named_parameters():\n",
    "    if not p.requires_grad:\n",
    "        continue\n",
    "    (backbone if n.startswith(\"rgb_enc\") else head).append(p)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": backbone, \"lr\": cfg.LR * 0.3}, \n",
    "        {\"params\": head,     \"lr\": cfg.LR},\n",
    "    ],\n",
    "    weight_decay=cfg.WD\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(cfg.AMP and device.type == \"cuda\"))\n",
    "\n",
    "best_f1 = -1.0\n",
    "best_path = os.path.join(cfg.OUT_DIR, cfg.BEST_CKPT)\n",
    "\n",
    "for ep in range(1, cfg.EPOCHS + 1):\n",
    "    tr_loss = train_one_epoch(model, dl_tr, optimizer, scaler if scaler.is_enabled() else None, device)\n",
    "    metrics = evaluate(model, dl_va, device)\n",
    "    print(f\"Epoch {ep:02d} | loss={tr_loss:.4f} | val_acc={metrics['acc']:.4f} | val_macroF1={metrics['macro_f1']:.4f}\")\n",
    "\n",
    "    if metrics[\"macro_f1\"] > best_f1:\n",
    "        best_f1 = metrics[\"macro_f1\"]\n",
    "        torch.save({\"model\": model.state_dict(), \"hs_in_ch\": hs_in_ch, \"cfg\": cfg.__dict__}, best_path)\n",
    "        print(f\"  -> saved best to {best_path}\")\n",
    "\n",
    "ckpt = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "\n",
    "pred_ids, pred_labels = predict(model, dl_te, device)\n",
    "\n",
    "\n",
    "sub_ids = []\n",
    "for _, r in val_df.iterrows():\n",
    "    if isinstance(r.get(\"hs\"), str) and r.get(\"hs\"):\n",
    "        sub_ids.append(os.path.basename(r[\"hs\"]))\n",
    "    elif isinstance(r.get(\"ms\"), str) and r.get(\"ms\"):\n",
    "        sub_ids.append(os.path.basename(r[\"ms\"]))\n",
    "    else:\n",
    "        sub_ids.append(os.path.basename(r[\"rgb\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "968a1231",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:26:46.222970Z",
     "iopub.status.busy": "2026-01-02T03:26:46.222223Z",
     "iopub.status.idle": "2026-01-02T03:26:46.239492Z",
     "shell.execute_reply": "2026-01-02T03:26:46.238905Z"
    },
    "papermill": {
     "duration": 0.026778,
     "end_time": "2026-01-02T03:26:46.241079",
     "exception": false,
     "start_time": "2026-01-02T03:26:46.214301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"Id\": sub_ids, \"Category\": pred_labels})\n",
    "out_csv = os.path.join(cfg.OUT_DIR, \"submission.csv\")\n",
    "sub.to_csv(out_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b10bf00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T03:26:46.254934Z",
     "iopub.status.busy": "2026-01-02T03:26:46.254654Z",
     "iopub.status.idle": "2026-01-02T03:26:46.274690Z",
     "shell.execute_reply": "2026-01-02T03:26:46.273943Z"
    },
    "papermill": {
     "duration": 0.028465,
     "end_time": "2026-01-02T03:26:46.276293",
     "exception": false,
     "start_time": "2026-01-02T03:26:46.247828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_000a83c1.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_00a704b1.tif</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_01dde030.tif</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id Category\n",
       "0  val_000a83c1.tif   Health\n",
       "1  val_00a704b1.tif    Other\n",
       "2  val_01dde030.tif     Rust"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14953781,
     "sourceId": 126119,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1191.965873,
   "end_time": "2026-01-02T03:26:49.201520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T03:06:57.235647",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "030f6d3c970f4b4683cd51244f1cdfb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ed13d7f620ee402fa5ee572409d3c1f4",
       "placeholder": "​",
       "style": "IPY_MODEL_ddb40d96a692446eb1f20c6661c14c0a",
       "tabbable": null,
       "tooltip": null,
       "value": " 354M/354M [00:02&lt;00:00, 456MB/s]"
      }
     },
     "3e5185296cee4b21b02a952778e1f52f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4dfc04b8d9254b97ae3388db4bc33d3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7476c0297ca644849af47c12e96ae2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3e5185296cee4b21b02a952778e1f52f",
       "placeholder": "​",
       "style": "IPY_MODEL_4dfc04b8d9254b97ae3388db4bc33d3f",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "9da7c77c3c904271a56862db18f364e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7476c0297ca644849af47c12e96ae2e5",
        "IPY_MODEL_b06c65b66001406ea10ab6d0fdab3922",
        "IPY_MODEL_030f6d3c970f4b4683cd51244f1cdfb9"
       ],
       "layout": "IPY_MODEL_f8eec2ad30414b9b8c2e6801176f39c0",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a9632d2a792341a1b43cf09df07ca914": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b06c65b66001406ea10ab6d0fdab3922": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c0dec83119c4467dbf446c4e3cef5f00",
       "max": 354400320.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a9632d2a792341a1b43cf09df07ca914",
       "tabbable": null,
       "tooltip": null,
       "value": 354400320.0
      }
     },
     "c0dec83119c4467dbf446c4e3cef5f00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddb40d96a692446eb1f20c6661c14c0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ed13d7f620ee402fa5ee572409d3c1f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8eec2ad30414b9b8c2e6801176f39c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
