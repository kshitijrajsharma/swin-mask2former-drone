{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High res drone imagery with TorchGeo\n",
    "\n",
    "This notebook demonstrates how to use the `OpenAerialMap` dataset in TorchGeo to train a instance segmentation model for building detection.\n",
    "\n",
    "**Features showcased:**\n",
    "1. **Catalog Search:** Querying available imagery using the new `search=True` mode.\n",
    "2. **Data Download:** Downloading specific high-resolution drone imagery.\n",
    "3. **Intersection Dataset:** combining raster (OAM) and vector (OSM) data.\n",
    "\n",
    "\n",
    "The system combines a hierarchical vision transformer backbone with an instance segmentation head to predict individual building footprints from aerial imagery. The architecture is implemented in the `Mask2FormerModule` class and consists of three main components:\n",
    "\n",
    "1. **Swin Transformer V2 Backbone**: Extracts multi-scale features using window-based self-attention\n",
    "2. **Mask2Former Decoder**: Generates instance-level predictions via learnable queries\n",
    "3. **Multi-Component Loss**: Optimizes for classification, overlap, and geometric precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from torchgeo.datasets import OpenStreetMap, OpenAerialMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Region of Interest\n",
    "\n",
    "We define a bounding box for **Banepa Municipality, Nepal**. This area has good drone coverage in OpenAerialMap.\n",
    "\n",
    "![image.png](docs/train_val.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = Path('data/banepa')\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_BBOX = [\n",
    "  85.51176609880189,\n",
    "  27.625518932561256,\n",
    "  85.52513148143508,\n",
    "  27.63551883131749\n",
    "]\n",
    "\n",
    "TEST_BBOX = [\n",
    "  85.53039880381334,\n",
    "  27.62456651360527,\n",
    "  85.53606027956683,\n",
    "  27.629042810653335\n",
    "]\n",
    "\n",
    "VAL_BBOX = [\n",
    "  85.51883176039746,\n",
    "  27.63560,\n",
    "  85.52308324197179,\n",
    "  27.63833629629815\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Browse Available Imagery\n",
    "\n",
    "We use `search=True` to query the catalog without downloading files. This allows us to inspect metadata and choose the best image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for available images...\n",
      "Found 4 available images\n",
      "\n",
      "Use .search_results to view.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Provider</th>\n",
       "      <th>GSD</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6708341a4a0ab60001b0b94d</td>\n",
       "      <td>2024-10-10T20:07:54.049+00:00</td>\n",
       "      <td>satellite</td>\n",
       "      <td>Maxar</td>\n",
       "      <td>0.345278</td>\n",
       "      <td>Maxar 105001003E1F0500 Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67084ad84a0ab60001b0b95b</td>\n",
       "      <td>2024-10-10T21:44:56.060+00:00</td>\n",
       "      <td>satellite</td>\n",
       "      <td>Maxar</td>\n",
       "      <td>0.345283</td>\n",
       "      <td>Maxar 1040010095519A00 Nepal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62d86c65d8499800053796c4</td>\n",
       "      <td>2022-04-15T19:00:00Z</td>\n",
       "      <td>uav</td>\n",
       "      <td>Geomatics Engineering Society</td>\n",
       "      <td>0.031627</td>\n",
       "      <td>UAV Images of Banepa Municipality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59e62b743d6412ef72209204</td>\n",
       "      <td></td>\n",
       "      <td>satellite</td>\n",
       "      <td>Digital Globe</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15APR27052125-S3DS_R14C5-054335918020_01_P001.TIF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID                           Date   Platform  \\\n",
       "0  6708341a4a0ab60001b0b94d  2024-10-10T20:07:54.049+00:00  satellite   \n",
       "1  67084ad84a0ab60001b0b95b  2024-10-10T21:44:56.060+00:00  satellite   \n",
       "2  62d86c65d8499800053796c4           2022-04-15T19:00:00Z        uav   \n",
       "3  59e62b743d6412ef72209204                                 satellite   \n",
       "\n",
       "                        Provider       GSD  \\\n",
       "0                          Maxar  0.345278   \n",
       "1                          Maxar  0.345283   \n",
       "2  Geomatics Engineering Society  0.031627   \n",
       "3                  Digital Globe  0.400000   \n",
       "\n",
       "                                               Title  \n",
       "0                       Maxar 105001003E1F0500 Nepal  \n",
       "1                       Maxar 1040010095519A00 Nepal  \n",
       "2                  UAV Images of Banepa Municipality  \n",
       "3  15APR27052125-S3DS_R14C5-054335918020_01_P001.TIF  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Searching for available images...')\n",
    "browser = OpenAerialMap(paths=WORK_DIR, bbox=TRAIN_BBOX, search=True, max_items=5)\n",
    "\n",
    "if browser.search_results is not None:\n",
    "    display(browser.search_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Datasets\n",
    "\n",
    "We select a specific Image ID from the search results above and download it.\n",
    "We also download OpenStreetMap building footprints for the same area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = [TRAIN_BBOX, VAL_BBOX, TEST_BBOX ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing OpenAerialMap (Image Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Collection: openaerialmap\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 378 tiles...\n",
      "Finished downloading 378 tiles.\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Collection: openaerialmap\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 40 tiles...\n",
      "Finished downloading 40 tiles.\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n",
      "Using OpenAerialMap image: UAV Images of Banepa Municipality\n",
      "  ID: 62d86c65d8499800053796c4\n",
      "  Collection: openaerialmap\n",
      "  Date: 2022-04-15T19:00:00Z\n",
      "  Platform: uav\n",
      "  Provider: Geomatics Engineering Society\n",
      "  GSD: 0.0316273953754\n",
      "  License: CC-BY-4.0\n",
      "Starting download of 72 tiles...\n",
      "Finished downloading 72 tiles.\n",
      "Download complete.\n",
      "Initializing OpenStreetMap (Mask Layer)...\n"
     ]
    }
   ],
   "source": [
    "# Selected Image ID (from search results above)\n",
    "IMAGE_ID = '62d86c65d8499800053796c4'\n",
    "ZOOM_LEVEL = 19\n",
    "CHIP_SIZE_PX = 512\n",
    "\n",
    "print('Initializing OpenAerialMap (Image Layer)...')\n",
    "\n",
    "\n",
    "folder = ['train', 'val', 'test']\n",
    "\n",
    "i = 0\n",
    "for bbox_d in all_datasets:\n",
    "    oam_dataset = OpenAerialMap(\n",
    "        paths=os.path.join(WORK_DIR,folder[i],'source'),\n",
    "        bbox=bbox_d,\n",
    "        zoom=ZOOM_LEVEL,\n",
    "        download=True,\n",
    "        image_id=IMAGE_ID,\n",
    "        tile_size=CHIP_SIZE_PX,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print('Initializing OpenStreetMap (Mask Layer)...')\n",
    "    OSM_CLASSES = [{'name': 'building', 'selector': [{'building': '*'}]}]\n",
    "\n",
    "    osm_dataset = OpenStreetMap(\n",
    "        paths=os.path.join(WORK_DIR, folder[i], 'labels'), bbox=bbox_d, classes=OSM_CLASSES, download=True\n",
    "    )\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intersection Dataset & Sampler\n",
    "\n",
    "We use the `&` operator to create an IntersectionDataset. This ensures every sample contains both imagery and a corresponding mask. this is done inside the package , lets initialize the configuration with dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(data_root=PosixPath('data/banepa'), output_dir='outputs/banepa_experiment', seed=64, train_regions=['train'], val_regions=['val'], test_regions=['test'], val_split=0.2, pretrained_model='facebook/mask2former-swin-base-IN21k-coco-instance', epochs=50, batch_size=8, dice_weight=5.0, mask_weight=5.0, class_weight=5.0, boundary_loss_weight=5.0, learning_rate=1e-05, weight_decay=0.0001, early_stopping_patience=10, num_workers=31, use_wandb=False, wandb_project='building-seg-mask2former', wandb_run_name='notebook_run_banepa')\n"
     ]
    }
   ],
   "source": [
    "from src.config import Config\n",
    "\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "cfg.data_root = WORK_DIR\n",
    "cfg.output_dir = 'outputs/banepa_experiment'\n",
    "cfg.train_regions = ['train']\n",
    "cfg.val_regions = ['val']\n",
    "cfg.test_regions = ['test']\n",
    "cfg.wandb_run_name='notebook_run_banepa'\n",
    "cfg.use_wandb = False \n",
    "\n",
    "\n",
    "cfg.epochs = 50\n",
    "\n",
    "cfg.boundary_loss_weight = 5.0\n",
    "\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Setup\n",
    "\n",
    "The `Mask2FormerModule` class wraps the pretrained `Mask2FormerForUniversalSegmentation` model from Hugging Face Transformers. Model configuration occurs in the `__init__` method:\n",
    "\n",
    "| Configuration Parameter | Value | Purpose |\n",
    "|------------------------|-------|---------|\n",
    "| `pretrained_model` | `facebook/mask2former-swin-base-IN21k-coco-instance` | Base model with ImageNet-22K pretrained backbone |\n",
    "| `num_labels` | 2 | Binary classification: background (0), building (1) |\n",
    "| `ignore_index` | 255 | Label value to ignore in loss computation (empty masks) |\n",
    "| `class_weight` | 5.0 (default) | Weight for classification loss component |\n",
    "| `dice_weight` | 5.0 (default) | Weight for Dice loss component |\n",
    "| `mask_weight` | 5.0 (default) | Weight for mask loss component |\n",
    "\n",
    "The model is initialized from pretrained weights with `ignore_mismatched_sizes=True` to accommodate the change from COCO's 80 classes to binary classification.\n",
    "\n",
    "![arch](docs/transformer_arc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krschap/code/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/krschap/code/foss/high-res-building-seg-swinv2-mask2former/.venv/lib/python3.13/site-packages/transformers/image_processing_base.py:417: UserWarning: The following named arguments are not valid for `Mask2FormerImageProcessor.__init__` and were ignored: '_max_size', 'reduce_labels'\n",
      "  image_processor = cls(**image_processor_dict)\n",
      "Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-base-IN21k-coco-instance and are newly initialized because the shapes did not match:\n",
      "- class_predictor.weight: found shape torch.Size([81, 256]) in the checkpoint and torch.Size([3, 256]) in the model instantiated\n",
      "- class_predictor.bias: found shape torch.Size([81]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- criterion.empty_weight: found shape torch.Size([81]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import set_seed\n",
    "from src.stage1_foundation import Mask2FormerModule\n",
    "from src.stage1_foundation import OAMDataModule\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "model = Mask2FormerModule(cfg)\n",
    "datamodule = OAMDataModule(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses the AdamW optimizer with cosine annealing learning rate schedule, configured in the `configure_optimizers()` method:\n",
    "\n",
    "| Parameter | Default Value | Description |\n",
    "|-----------|---------------|-------------|\n",
    "| Optimizer | AdamW | Weight decay variant of Adam |\n",
    "| Learning Rate | 1e-5 | Initial learning rate from `cfg.learning_rate` |\n",
    "| Weight Decay | 1e-4 | L2 regularization penalty from `cfg.weight_decay` |\n",
    "| Scheduler | CosineAnnealingLR | Gradually reduces LR to 0 over training |\n",
    "| T_max | `cfg.epochs` | Number of epochs for full cosine cycle |\n",
    "\n",
    "The cosine annealing schedule provides:\n",
    "- Smooth learning rate decay from initial value to near-zero\n",
    "- Better convergence properties than step decay\n",
    "- No need for manual LR adjustment during training\n",
    "\n",
    "The scheduler updates once per epoch (`interval=\"epoch\"`, `frequency=1`) with strict enforcement of the schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=cfg.early_stopping_patience,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=cfg.output_dir,\n",
    "        filename=\"best\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "    ),\n",
    "]\n",
    "\n",
    "logger = (\n",
    "    WandbLogger(project=cfg.wandb_project, name=cfg.wandb_run_name)\n",
    "    if cfg.use_wandb\n",
    "    else None\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.epochs,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    precision=\"16-mixed\",\n",
    "    default_root_dir=cfg.output_dir,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test & Visualize Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule, ckpt_path=\"best\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "**Instance-Level (AP/mAP)** - Evaluates each building separately:\n",
    "- `map` - mAP @ IoU 0.50:0.95 (strict, best for boundaries)\n",
    "- `map_50` - mAP @ IoU 0.50 (detection quality)\n",
    "\n",
    "**Pixel-Level (Binary)** - Overall coverage:\n",
    "- `iou` - Intersection over Union\n",
    "- `f1` - F1 score\n",
    "- `acc` - Accuracy\n",
    "\n",
    "For building boundaries & separation, prioritize **`map`** and **`map_50`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup()\n",
    "batch = next(iter(datamodule.test_dataloader()))\n",
    "model.visualize_batch(batch, num_samples=5, save_path=\"test_results.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "high-res-building-seg-swinv2-mask2former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
